<!DOCTYPE html>
<!--[if IE 8]> <html lang="en" class="ie8 no-js"> <![endif]-->
<!--[if IE 9]> <html lang="en" class="ie9 no-js"> <![endif]-->
<!--[if !IE]><!-->
<html lang="en">
<!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <title>Kuzma&#39;s Blog</title>

  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta property="og:type" content="website">
<meta property="og:title" content="Kuzma&#39;s Blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Kuzma&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Kuzma">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="/favicon.ico">
  
    
  <meta content="{{ title }}" name="description">
  <meta content="{{ title }}" name="keywords">
  <meta content="{{ title }}" name="author">

  <link href="http://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700|PT+Sans+Narrow|Source+Sans+Pro:200,300,400,600,700,900&amp;subset=all" rel="stylesheet" type="text/css">

  <!-- Global styles START -->   
  
<link rel="stylesheet" href="/metronic/assets/plugins/font-awesome/css/font-awesome.min.css">

  
<link rel="stylesheet" href="/metronic/assets/plugins/bootstrap/css/bootstrap.min.css">

  <!-- Global styles END --> 
   
  <!-- Page level plugin styles START -->
  
<link rel="stylesheet" href="/metronic/assets/pages/css/animate.css">

  
<link rel="stylesheet" href="/metronic/assets/plugins/owl.carousel/assets/owl.carousel.css">

  <!-- Page level plugin styles END -->

  <!-- Theme styles START -->
  
<link rel="stylesheet" href="/metronic/assets/pages/css/components.css">

  
<link rel="stylesheet" href="/metronic/assets/pages/css/slider.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/style.css">

  
<link rel="stylesheet" href="/metronic/assets/pages/css/portfolio.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/style-responsive.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/themes/red.css">

  
<link rel="stylesheet" href="/css/theme-styles.css">

  <!-- Theme styles END -->
<meta name="generator" content="Hexo 5.2.0"></head>

<body class="corporate">
  <!-- BEGIN TOP BAR -->
<div class="pre-header">
  <div class="container">
    <div class="row">
      <!-- BEGIN TOP BAR LEFT PART -->
      <div class="col-md-6 col-sm-6 col-xs-9 additional-shop-info">
	<ul class="list-unstyled list-inline">
	  <li><i class="fa fa-phone"></i><span></span></li>
	  <li><i class="fa fa-envelope-o"></i><span></span></li>
	</ul>
      </div>
      <!-- END TOP BAR LEFT PART -->
      <!-- BEGIN TOP BAR MENU -->
      <div class="col-md-6 col-sm-6 col-xs-3 additional-nav">
	<ul class="list-unstyled list-inline pull-right">
	  <li><a href="/login">Log In</a></li>
	</ul>
      </div>
      <!-- END TOP BAR MENU -->
    </div>
  </div>        
</div>
<!-- END TOP BAR -->
<!-- BEGIN HEADER -->
<div class="header">
  <div class="container">
    <!--<a class="site-logo" href="/" id="logo">Kuzma&#39;s Blog</a>-->

    <a class="site-logo" href="/">
      <img src="/metronic/assets/corporate/img/logos/logo-corp-red.png" alt="Metronic FrontEnd">
    </a>

    <a href="javascript:void(0);" class="mobi-toggler"><i class="fa fa-bars"></i></a>

    <!-- BEGIN NAVIGATION -->
    <div class="header-navigation pull-right font-transform-inherit">
      <ul>
	
	<li class="active">
	  <a  href="/">Home</a>
	</li>
	
	<li class="">
	  <a  href="/archives/">Blog</a>
	</li>
	
	<li class="">
	  <a  href="/about/">About</a>
	</li>
	
	<!-- BEGIN TOP SEARCH -->
	<li class="menu-search">
	  <span class="sep"></span>
	  <i class="fa fa-search search-btn"></i>
	  <div class="search-box">
	    <form action="#">
	      <div class="input-group">
		<input type="text" placeholder="Search" class="form-control st-default-search-input">
		<span class="input-group-btn">
		  <button class="btn btn-primary" type="submit">Search</button>
		</span>
	      </div>
	    </form>
	  </div> 
	</li>
	<!-- END TOP SEARCH -->
      </ul>
    </div>
    <!-- END NAVIGATION -->
  </div>
</div>
<!-- Header END -->

  
  <div class="container">
    <ul class="breadcrumb">
      <li class="active">Home</li>
    </ul>
  <div id="main">
    <div class="row">

<div class="col-xs-12 blog-posts">


  <section class="archives-wrap">
    <div class="archives">
      
	<div class="row">
  <div class="col-md-4 col-sm-4">
    
  </div>
  
    <div class="col-xs-12">
  
    
    <h2 itemprop="name">
      <a class="archive-article-title" href="/2020/10/14/Coding-Demonstration/">Coding Demonstration</a>
    </h2>


    <ul class="blog-info">
      <li>
      	<i class="fa fa-calendar"></i> 
        <time datetime="2020-10-14T07:37:29.000Z" itemprop="datePublished">2020/10/14</time>

      </li>
      <li><i class="fa fa-comments"></i>
        <a href="http://example.com/2020/10/14/Coding-Demonstration/#disqus_thread" class="article-comment-link">Comments</a>
      </li>
      <li>
	<i class="fa fa-tags"></i>
	

      </li>
    </ul>
    <div class="blog-item">
      
	<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1. python 2. stata 3. R</span></span><br><span class="line"><span class="comment"># jupyter notebook</span></span><br><span class="line"><span class="comment">#package</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#import plotly.graph_objs as go</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="comment">#import plotly as py</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># y_head = w1* x_1 + w* x_2  + ... + w_n * x_n  + b(bias)</span></span><br><span class="line"><span class="comment"># linear model vs. non-linear model</span></span><br><span class="line"><span class="comment"># aboslute file path and  local file path</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;online_shoppers_intention.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> (data)</span><br></pre></td></tr></table></figure>

<pre><code>       Administrative  Administrative_Duration  Informational  \
0                   0                      0.0              0   
1                   0                      0.0              0   
2                   0                      0.0              0   
3                   0                      0.0              0   
4                   0                      0.0              0   
...               ...                      ...            ...   
12325               3                    145.0              0   
12326               0                      0.0              0   
12327               0                      0.0              0   
12328               4                     75.0              0   
12329               0                      0.0              0   

       Informational_Duration  ProductRelated  ProductRelated_Duration  \
0                         0.0               1                 0.000000   
1                         0.0               2                64.000000   
2                         0.0               1                 0.000000   
3                         0.0               2                 2.666667   
4                         0.0              10               627.500000   
...                       ...             ...                      ...   
12325                     0.0              53              1783.791667   
12326                     0.0               5               465.750000   
12327                     0.0               6               184.250000   
12328                     0.0              15               346.000000   
12329                     0.0               3                21.250000   

       BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \
0         0.200000   0.200000    0.000000         0.0   Feb                 1   
1         0.000000   0.100000    0.000000         0.0   Feb                 2   
2         0.200000   0.200000    0.000000         0.0   Feb                 4   
3         0.050000   0.140000    0.000000         0.0   Feb                 3   
4         0.020000   0.050000    0.000000         0.0   Feb                 3   
...            ...        ...         ...         ...   ...               ...   
12325     0.007143   0.029031   12.241717         0.0   Dec                 4   
12326     0.000000   0.021333    0.000000         0.0   Nov                 3   
12327     0.083333   0.086667    0.000000         0.0   Nov                 3   
12328     0.000000   0.021053    0.000000         0.0   Nov                 2   
12329     0.000000   0.066667    0.000000         0.0   Nov                 3   

       Browser  Region  TrafficType        VisitorType  Weekend  Revenue  
0            1       1            1  Returning_Visitor    False    False  
1            2       1            2  Returning_Visitor    False    False  
2            1       9            3  Returning_Visitor    False    False  
3            2       2            4  Returning_Visitor    False    False  
4            3       1            4  Returning_Visitor     True    False  
...        ...     ...          ...                ...      ...      ...  
12325        6       1            1  Returning_Visitor     True    False  
12326        2       1            8  Returning_Visitor     True    False  
12327        2       1           13  Returning_Visitor     True    False  
12328        2       3           11  Returning_Visitor    False    False  
12329        2       1            2        New_Visitor     True    False  

[12330 rows x 18 columns]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> (data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(12330, 18)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hetergenous data type(heter vs. homo)</span></span><br><span class="line"><span class="keyword">print</span> (data.head())</span><br></pre></td></tr></table></figure>

<pre><code>   Administrative  Administrative_Duration  Informational  \
0               0                      0.0              0   
1               0                      0.0              0   
2               0                      0.0              0   
3               0                      0.0              0   
4               0                      0.0              0   

   Informational_Duration  ProductRelated  ProductRelated_Duration  \
0                     0.0               1                 0.000000   
1                     0.0               2                64.000000   
2                     0.0               1                 0.000000   
3                     0.0               2                 2.666667   
4                     0.0              10               627.500000   

   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \
0         0.20       0.20         0.0         0.0   Feb                 1   
1         0.00       0.10         0.0         0.0   Feb                 2   
2         0.20       0.20         0.0         0.0   Feb                 4   
3         0.05       0.14         0.0         0.0   Feb                 3   
4         0.02       0.05         0.0         0.0   Feb                 3   

   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  
0        1       1            1  Returning_Visitor    False    False  
1        2       1            2  Returning_Visitor    False    False  
2        1       9            3  Returning_Visitor    False    False  
3        2       2            4  Returning_Visitor    False    False  
4        3       1            4  Returning_Visitor     True    False  </code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># data set</span></span><br><span class="line"><span class="comment"># 1. hetergeneouse data type </span></span><br><span class="line"><span class="comment"># 2. missing values </span></span><br><span class="line"><span class="comment"># 3. irregular sampling </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># data preprocessing </span></span><br><span class="line"><span class="comment"># 1. data imputation:  1. impute 0 2. impute mean/medium 3. guassian imputation  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># data visulization</span></span><br><span class="line"><span class="comment">#print (data.describe())</span></span><br><span class="line"><span class="comment"># 1. list 2. array 3. dataframe</span></span><br><span class="line"><span class="comment"># check if the data contains any missing values (null)</span></span><br><span class="line"><span class="keyword">print</span> (data.isnull().sum().sum())</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>0</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># data visulaization</span></span><br><span class="line"><span class="comment">#matplotlib</span></span><br><span class="line"><span class="comment"># checking the Distribution of customers on Revenue</span></span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">18</span>, <span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sns.countplot(data[<span class="string">&#x27;Weekend&#x27;</span>], palette = <span class="string">&#x27;pastel&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Buy or Not&#x27;</span>, fontsize = <span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Revenue or not&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;count&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># checking the Distribution of customers on Weekend</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">sns.countplot(data[<span class="string">&#x27;Weekend&#x27;</span>], palette = <span class="string">&#x27;inferno&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Purchase on Weekends&#x27;</span>, fontsize = <span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Weekend or not&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;count&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="/2020/10/14/Coding-Demonstration/output_6_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plotting a pie chart for browsers</span></span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">18</span>, <span class="number">7</span>)</span><br><span class="line">size = [<span class="number">10551</span>, <span class="number">1694</span>, <span class="number">85</span>]</span><br><span class="line">colors = [<span class="string">&#x27;violet&#x27;</span>, <span class="string">&#x27;magenta&#x27;</span>, <span class="string">&#x27;pink&#x27;</span>]</span><br><span class="line">labels = <span class="string">&quot;Returning Visitor&quot;</span>, <span class="string">&quot;New_Visitor&quot;</span>, <span class="string">&quot;Others&quot;</span></span><br><span class="line">explode = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0.1</span>]</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.pie(size, colors = colors, labels = labels, explode = explode, shadow = <span class="literal">True</span>, autopct = <span class="string">&#x27;%.2f%%&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Different Visitors&#x27;</span>, fontsize = <span class="number">20</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># plotting a pie chart for browsers</span></span><br><span class="line">size = [<span class="number">7961</span>, <span class="number">2462</span>, <span class="number">736</span>, <span class="number">467</span>,<span class="number">174</span>, <span class="number">163</span>, <span class="number">300</span>]</span><br><span class="line">colors = [<span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;yellow&#x27;</span>, <span class="string">&#x27;pink&#x27;</span>, <span class="string">&#x27;crimson&#x27;</span>, <span class="string">&#x27;lightgreen&#x27;</span>, <span class="string">&#x27;cyan&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>]</span><br><span class="line">labels = <span class="string">&quot;2&quot;</span>, <span class="string">&quot;1&quot;</span>,<span class="string">&quot;4&quot;</span>,<span class="string">&quot;5&quot;</span>,<span class="string">&quot;6&quot;</span>,<span class="string">&quot;10&quot;</span>,<span class="string">&quot;others&quot;</span></span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.pie(size, colors = colors, labels = labels, shadow = <span class="literal">True</span>, autopct = <span class="string">&#x27;%.2f%%&#x27;</span>, startangle = <span class="number">90</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Different Browsers&#x27;</span>, fontsize = <span class="number">20</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#supply &amp; demand</span></span><br><span class="line"><span class="comment"># classification customers -&gt; machine learning -&gt;  interdiscinpinary study -&gt; prediction</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="/2020/10/14/Coding-Demonstration/output_7_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># environment is higly dybamic-&gt; update information as soon as possible </span></span><br><span class="line"><span class="comment">#big data: 1. data volum 2. data types 3. data variabllity </span></span><br><span class="line"><span class="comment"># revenue: objective: maxmize the revenue -&gt; 1. prediction 2. reduce cost -&gt; modelling</span></span><br><span class="line"><span class="comment"># visualizing the distribution of customers around the Region</span></span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">18</span>, <span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.hist(data[<span class="string">&#x27;TrafficType&#x27;</span>], color = <span class="string">&#x27;lightgreen&#x27;</span>)<span class="comment"># hist =&gt; histgram </span></span><br><span class="line">plt.title(<span class="string">&#x27;Distribution of diff Traffic&#x27;</span>,fontsize = <span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;TrafficType Codes&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Count&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># visualizing the distribution of customers around the Region</span></span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.hist(data[<span class="string">&#x27;Region&#x27;</span>], color = <span class="string">&#x27;lightblue&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Distribution of Customers&#x27;</span>,fontsize = <span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Region Codes&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Count&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/2020/10/14/Coding-Demonstration/output_8_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># x: independent variables </span></span><br><span class="line"><span class="comment">#y: dependent variables </span></span><br><span class="line"><span class="comment"># bias: control variables </span></span><br><span class="line"><span class="comment"># linear model</span></span><br><span class="line"><span class="comment">#homework: </span></span><br><span class="line"><span class="comment">#1. run all the code </span></span><br><span class="line"><span class="comment"># 2. machine learning: understand what is a model? </span></span><br><span class="line"><span class="comment"># 3. a. supervised learning b. unsupervosed learning c. reinforcement learning (optional)</span></span><br><span class="line"><span class="comment"># 4. any ideas about all this graph: (critical thinkings)</span></span><br><span class="line"><span class="comment"># creating a donut chart for the months variations&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># plotting a pie chart for different number of OSes users have.</span></span><br><span class="line"></span><br><span class="line">size = [<span class="number">6601</span>, <span class="number">2585</span>, <span class="number">2555</span>, <span class="number">478</span>, <span class="number">111</span>]</span><br><span class="line">colors = [<span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;yellow&#x27;</span>, <span class="string">&#x27;pink&#x27;</span>, <span class="string">&#x27;crimson&#x27;</span>, <span class="string">&#x27;lightgreen&#x27;</span>]</span><br><span class="line">labels = <span class="string">&quot;2&quot;</span>, <span class="string">&quot;1&quot;</span>,<span class="string">&quot;3&quot;</span>,<span class="string">&quot;4&quot;</span>,<span class="string">&quot;others&quot;</span></span><br><span class="line">explode = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">circle = plt.Circle((<span class="number">0</span>, <span class="number">0</span>), <span class="number">0.6</span>, color = <span class="string">&#x27;white&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.pie(size, colors = colors, labels = labels, explode = explode, shadow = <span class="literal">True</span>, autopct = <span class="string">&#x27;%.2f%%&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;OSes Users have&#x27;</span>, fontsize = <span class="number">30</span>)</span><br><span class="line">p = plt.gcf()</span><br><span class="line">p.gca().add_artist(circle)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># plotting a pie chart for share of special days</span></span><br><span class="line"></span><br><span class="line">size = [<span class="number">3364</span>, <span class="number">2998</span>, <span class="number">1907</span>, <span class="number">1727</span>, <span class="number">549</span>, <span class="number">448</span>, <span class="number">433</span>, <span class="number">432</span>, <span class="number">288</span>, <span class="number">184</span>]</span><br><span class="line">colors = [<span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;yellow&#x27;</span>, <span class="string">&#x27;pink&#x27;</span>, <span class="string">&#x27;crimson&#x27;</span>, <span class="string">&#x27;lightgreen&#x27;</span>, <span class="string">&#x27;cyan&#x27;</span>, <span class="string">&#x27;magenta&#x27;</span>, <span class="string">&#x27;lightblue&#x27;</span>, <span class="string">&#x27;lightgreen&#x27;</span>, <span class="string">&#x27;violet&#x27;</span>]</span><br><span class="line">labels = <span class="string">&quot;May&quot;</span>, <span class="string">&quot;November&quot;</span>, <span class="string">&quot;March&quot;</span>, <span class="string">&quot;December&quot;</span>, <span class="string">&quot;October&quot;</span>, <span class="string">&quot;September&quot;</span>, <span class="string">&quot;August&quot;</span>, <span class="string">&quot;July&quot;</span>, <span class="string">&quot;June&quot;</span>, <span class="string">&quot;February&quot;</span></span><br><span class="line">explode = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">circle = plt.Circle((<span class="number">0</span>, <span class="number">0</span>), <span class="number">0.6</span>, color = <span class="string">&#x27;white&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.pie(size, colors = colors, labels = labels, explode = explode, shadow = <span class="literal">True</span>, autopct = <span class="string">&#x27;%.2f%%&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Special Days&#x27;</span>, fontsize = <span class="number">30</span>)</span><br><span class="line">p = plt.gcf()</span><br><span class="line">p.gca().add_artist(circle)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="/2020/10/14/Coding-Demonstration/output_9_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># product related duration vs revenue</span></span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">18</span>, <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sns.boxenplot(data[<span class="string">&#x27;Revenue&#x27;</span>], data[<span class="string">&#x27;Informational_Duration&#x27;</span>], palette = <span class="string">&#x27;rainbow&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Info. duration vs Revenue&#x27;</span>, fontsize = <span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Info. duration&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Revenue&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># product related duration vs revenue</span></span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">sns.boxenplot(data[<span class="string">&#x27;Revenue&#x27;</span>], data[<span class="string">&#x27;Administrative_Duration&#x27;</span>], palette = <span class="string">&#x27;pastel&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Admn. duration vs Revenue&#x27;</span>, fontsize = <span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Admn. duration&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Revenue&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># product related duration vs revenue</span></span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">sns.boxenplot(data[<span class="string">&#x27;Revenue&#x27;</span>], data[<span class="string">&#x27;ProductRelated_Duration&#x27;</span>], palette = <span class="string">&#x27;dark&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Product Related duration vs Revenue&#x27;</span>, fontsize = <span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Product Related duration&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Revenue&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># exit rate vs revenue</span></span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">sns.boxenplot(data[<span class="string">&#x27;Revenue&#x27;</span>], data[<span class="string">&#x27;ExitRates&#x27;</span>], palette = <span class="string">&#x27;spring&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;ExitRates vs Revenue&#x27;</span>, fontsize = <span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;ExitRates&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Revenue&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="/2020/10/14/Coding-Demonstration/output_10_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># missing values?</span></span><br><span class="line"><span class="comment"># 1. data imputation (irregular data sampling) 2. missing values</span></span><br><span class="line"><span class="comment">#solution?</span></span><br><span class="line"><span class="comment">#1. impute 0 2. impute mean 3. guassian imputation </span></span><br><span class="line"><span class="comment"># deleting the entire row</span></span><br><span class="line"><span class="comment"># sklearn</span></span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="comment"># linear model vs. nonlinear model</span></span><br><span class="line"><span class="comment"># y = a1* x1 + a2 * x2 + ... + an*xn -&gt; multi-variable linear model to</span></span><br><span class="line"><span class="comment"># y = 1/ (1 + e^-x)</span></span><br><span class="line"><span class="comment"># stata - accounting  -&gt;  regression</span></span><br><span class="line"><span class="comment">#1. logistic regression 2. supoort vector machine 3. bernoullium mode 4. decsion treee 5. deep learning network (optional)</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># linear model vs. nonlinear model</span></span><br><span class="line"><span class="comment"># y = a1* x1 + a2 * x2 + ... + an*xn -&gt; multi-variable linear model to</span></span><br><span class="line"><span class="comment"># y = 1/ (1 + e^-x) -&gt; probability  -&gt; sigmoid</span></span><br><span class="line"><span class="comment"># tanh (range) (-1, 1)</span></span><br><span class="line"><span class="comment"># relu </span></span><br><span class="line"><span class="comment"># softmax</span></span><br><span class="line"><span class="comment"># 1. understand these four nonlinear transformation function </span></span><br><span class="line"><span class="comment"># logistic regression</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="comment"># handelling historical data</span></span><br><span class="line"><span class="comment"># nummeric vs. categorical data</span></span><br><span class="line"><span class="comment"># one-hot vector </span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line"></span><br><span class="line">bestfeature = SelectKBest(score_func = chi2, k = <span class="number">10</span>) <span class="comment"># deault parameters </span></span><br><span class="line"><span class="comment"># this is the deafult parameters for selecting the best features from the dataset</span></span><br><span class="line"><span class="comment"># 1. classification machine learning - 分类</span></span><br><span class="line"><span class="comment"># 2. regression maching leanring - 回归</span></span><br><span class="line"><span class="comment"># 3. reinforcement maching learning - 增强</span></span><br><span class="line"><span class="comment"># adaptive learning</span></span><br><span class="line"><span class="comment"># label: open label: (open dataset) </span></span><br><span class="line"><span class="comment"># majority vote: </span></span><br><span class="line"><span class="comment">#model: 一些参数加上某些数学的函数 -&gt; y </span></span><br><span class="line"><span class="comment"># softmax function </span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data1 = pd.get_dummies(data)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (data1.columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. approach 1</span></span><br><span class="line"><span class="keyword">print</span> (data[<span class="string">&#x27;Administrative&#x27;</span>].isnull())</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">&quot;step 2&quot;</span>)</span><br><span class="line"><span class="keyword">print</span> (data[<span class="string">&#x27;Administrative&#x27;</span>].isnull().values.any())</span><br><span class="line"><span class="comment"># 1. homework: tell me which column contain nan value </span></span><br><span class="line"><span class="keyword">print</span> (data[<span class="string">&#x27;Administrative_Duration&#x27;</span>].isnull().values.any())</span><br></pre></td></tr></table></figure>

<pre><code>Index([&#39;Administrative&#39;, &#39;Administrative_Duration&#39;, &#39;Informational&#39;,
       &#39;Informational_Duration&#39;, &#39;ProductRelated&#39;, &#39;ProductRelated_Duration&#39;,
       &#39;BounceRates&#39;, &#39;ExitRates&#39;, &#39;PageValues&#39;, &#39;SpecialDay&#39;,
       &#39;OperatingSystems&#39;, &#39;Browser&#39;, &#39;Region&#39;, &#39;TrafficType&#39;, &#39;Weekend&#39;,
       &#39;Revenue&#39;, &#39;Month_Aug&#39;, &#39;Month_Dec&#39;, &#39;Month_Feb&#39;, &#39;Month_Jul&#39;,
       &#39;Month_June&#39;, &#39;Month_Mar&#39;, &#39;Month_May&#39;, &#39;Month_Nov&#39;, &#39;Month_Oct&#39;,
       &#39;Month_Sep&#39;, &#39;VisitorType_New_Visitor&#39;, &#39;VisitorType_Other&#39;,
       &#39;VisitorType_Returning_Visitor&#39;],
      dtype=&#39;object&#39;)
0        False
1        False
2        False
3        False
4        False
         ...  
12325    False
12326    False
12327    False
12328    False
12329    False
Name: Administrative, Length: 12330, dtype: bool
step 2
False
False</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data[<span class="string">&#x27;Administrative_Duration&#x27;</span>])):</span><br><span class="line">    <span class="keyword">if</span> data[<span class="string">&#x27;Administrative_Duration&#x27;</span>][i] &lt;=<span class="number">0</span>:</span><br><span class="line">        data[<span class="string">&#x27;Administrative_Duration&#x27;</span>][i] = <span class="number">0</span> </span><br></pre></td></tr></table></figure>

<pre><code>/Users/hanzhongzheng/miniconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  after removing the cwd from sys.path.</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dummy variables: </span></span><br><span class="line"><span class="keyword">print</span> (data1)</span><br><span class="line"><span class="comment"># 1. dataset contains mixrture of number and text information -&gt; hetergenous datatype -&gt; modeling building challenge -&gt; matrix </span></span><br><span class="line"><span class="comment"># 2. high dimensionality -&gt; modelling building challenge. </span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>       Administrative  Administrative_Duration  Informational  \
0                   0                      0.0              0   
1                   0                      0.0              0   
2                   0                      0.0              0   
3                   0                      0.0              0   
4                   0                      0.0              0   
...               ...                      ...            ...   
12325               3                    145.0              0   
12326               0                      0.0              0   
12327               0                      0.0              0   
12328               4                     75.0              0   
12329               0                      0.0              0   

       Informational_Duration  ProductRelated  ProductRelated_Duration  \
0                         0.0               1                 0.000000   
1                         0.0               2                64.000000   
2                         0.0               1                 0.000000   
3                         0.0               2                 2.666667   
4                         0.0              10               627.500000   
...                       ...             ...                      ...   
12325                     0.0              53              1783.791667   
12326                     0.0               5               465.750000   
12327                     0.0               6               184.250000   
12328                     0.0              15               346.000000   
12329                     0.0               3                21.250000   

       BounceRates  ExitRates  PageValues  SpecialDay  ...  Month_Jul  \
0         0.200000   0.200000    0.000000         0.0  ...          0   
1         0.000000   0.100000    0.000000         0.0  ...          0   
2         0.200000   0.200000    0.000000         0.0  ...          0   
3         0.050000   0.140000    0.000000         0.0  ...          0   
4         0.020000   0.050000    0.000000         0.0  ...          0   
...            ...        ...         ...         ...  ...        ...   
12325     0.007143   0.029031   12.241717         0.0  ...          0   
12326     0.000000   0.021333    0.000000         0.0  ...          0   
12327     0.083333   0.086667    0.000000         0.0  ...          0   
12328     0.000000   0.021053    0.000000         0.0  ...          0   
12329     0.000000   0.066667    0.000000         0.0  ...          0   

       Month_June  Month_Mar  Month_May  Month_Nov  Month_Oct  Month_Sep  \
0               0          0          0          0          0          0   
1               0          0          0          0          0          0   
2               0          0          0          0          0          0   
3               0          0          0          0          0          0   
4               0          0          0          0          0          0   
...           ...        ...        ...        ...        ...        ...   
12325           0          0          0          0          0          0   
12326           0          0          0          1          0          0   
12327           0          0          0          1          0          0   
12328           0          0          0          1          0          0   
12329           0          0          0          1          0          0   

       VisitorType_New_Visitor  VisitorType_Other  \
0                            0                  0   
1                            0                  0   
2                            0                  0   
3                            0                  0   
4                            0                  0   
...                        ...                ...   
12325                        0                  0   
12326                        0                  0   
12327                        0                  0   
12328                        0                  0   
12329                        1                  0   

       VisitorType_Returning_Visitor  
0                                  1  
1                                  1  
2                                  1  
3                                  1  
4                                  1  
...                              ...  
12325                              1  
12326                              1  
12327                              1  
12328                              1  
12329                              0  

[12330 rows x 29 columns]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. data visualization: </span></span><br><span class="line"><span class="comment"># variable -&gt; multi-variate modelling </span></span><br><span class="line"><span class="comment"># 2. modelling -&gt; prediction -&gt; objective: to maximize the accuracy </span></span><br><span class="line"><span class="comment"># 1. dataset has deficts: data preprocessing: 1. data imputation 2. hetergeneous data type fusion 3. .... </span></span><br><span class="line"><span class="comment"># model building</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># label encoding of revenue</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">data = data1</span><br><span class="line">le = LabelEncoder()</span><br><span class="line">data[<span class="string">&#x27;Revenue&#x27;</span>] = le.fit_transform(data[<span class="string">&#x27;Revenue&#x27;</span>])</span><br><span class="line">data[<span class="string">&#x27;Revenue&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>0    10422
1     1908
Name: Revenue, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># getting dependent and independent variables</span></span><br><span class="line"></span><br><span class="line">x = data</span><br><span class="line"><span class="comment"># removing the target column revenue from x</span></span><br><span class="line">x = x.drop([<span class="string">&#x27;Revenue&#x27;</span>], axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">y = data[<span class="string">&#x27;Revenue&#x27;</span>]</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(y)):</span><br><span class="line">    <span class="keyword">if</span> y[i] == <span class="number">1</span>:</span><br><span class="line">        count = count + <span class="number">1</span></span><br><span class="line"><span class="keyword">print</span> (count)</span><br><span class="line"><span class="comment"># checking the shapes</span></span><br><span class="line">print(<span class="string">&quot;Shape of x:&quot;</span>, x.shape)</span><br><span class="line">print(<span class="string">&quot;Shape of y:&quot;</span>, y.shape)</span><br><span class="line"><span class="comment"># muli-variate regresion model </span></span><br><span class="line"><span class="comment"># y = w1* x*1 + w2* x2 + ... + w28 * x28</span></span><br></pre></td></tr></table></figure>

<pre><code>1908
Shape of x: (12330, 28)
Shape of y: (12330,)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># spliting data set into: train and test (train: 2/3 test: 1/3)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = <span class="number">0.333</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># checking the shapes</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Shape of x_train :&quot;</span>, x_train.shape)</span><br><span class="line">print(<span class="string">&quot;Shape of y_train :&quot;</span>, y_train.shape)</span><br><span class="line">print(<span class="string">&quot;Shape of x_test :&quot;</span>, x_test.shape)</span><br><span class="line">print(<span class="string">&quot;Shape of y_test :&quot;</span>, y_test.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Shape of x_train : (8224, 28)
Shape of y_train : (8224,)
Shape of x_test : (4106, 28)
Shape of y_test : (4106,)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. model : Descison Tree (决策树) -&gt; entropy</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="comment"># build random forest object</span></span><br><span class="line"><span class="comment"># default parameters -&gt; parameter tunning </span></span><br><span class="line">model_forest = RandomForestClassifier()</span><br><span class="line">print(model_forest)</span><br></pre></td></tr></table></figure>

<pre><code>RandomForestClassifier()</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train model </span></span><br><span class="line">model_forest.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>RandomForestClassifier()</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># this the model predict result </span></span><br><span class="line">y_predict = model_forest.predict(x_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="comment"># evaluating the model</span></span><br><span class="line">print(<span class="string">&quot;Training Accuracy :&quot;</span>, model_forest.score(x_train, y_train))</span><br><span class="line">print(<span class="string">&quot;Testing Accuracy :&quot;</span>, model_forest.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Homework (optional): confusion matrix </span></span><br><span class="line"><span class="comment"># confusion matrix</span></span><br><span class="line">cm = confusion_matrix(y_test, y_predict)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">sns.heatmap(cm ,annot = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># classification report</span></span><br><span class="line">cr = classification_report(y_test, y_predict)</span><br><span class="line">print(cr)</span><br></pre></td></tr></table></figure>

<pre><code>Training Accuracy : 1.0
Testing Accuracy : 0.8935703848027278
              precision    recall  f1-score   support

           0       0.92      0.96      0.94      3425
           1       0.74      0.55      0.63       681

    accuracy                           0.89      4106
   macro avg       0.83      0.76      0.79      4106
weighted avg       0.89      0.89      0.89      4106</code></pre>
<p><img src="/2020/10/14/Coding-Demonstration/output_22_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># feature selection to improve model performance</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line">sel = VarianceThreshold(threshold = (<span class="number">0.7</span> * (<span class="number">1</span> - <span class="number">0.70</span>)))</span><br><span class="line">sel.fit_transform(x)</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = <span class="number">0.333</span>, random_state = <span class="number">0</span>)</span><br><span class="line"><span class="comment"># train model </span></span><br><span class="line">model_forest.fit(x_train, y_train)</span><br><span class="line"><span class="comment"># this the model predict result </span></span><br><span class="line">y_predict = model_forest.predict(x_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="comment"># evaluating the model</span></span><br><span class="line">print(<span class="string">&quot;Training Accuracy :&quot;</span>, model_forest.score(x_train, y_train))</span><br><span class="line">print(<span class="string">&quot;Testing Accuracy :&quot;</span>, model_forest.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Homework (optional): confusion matrix </span></span><br><span class="line"><span class="comment"># confusion matrix</span></span><br><span class="line"><span class="comment"># TP, FN, FP, TN</span></span><br><span class="line"><span class="comment"># accuracy = (TP + TN)/(TP + FN + FP + TN)</span></span><br><span class="line"><span class="comment"># precision = (TP) / (TP + FP) </span></span><br><span class="line"><span class="comment"># recall = TP /(TP + FN)</span></span><br><span class="line"><span class="comment"># F1_score = 2 * TP/ (2* TP + FP + FN)</span></span><br><span class="line"><span class="comment"># evaluation metrics </span></span><br><span class="line">cm = confusion_matrix(y_test, y_predict)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">sns.heatmap(cm ,annot = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># classification report</span></span><br><span class="line">cr = classification_report(y_test, y_predict)</span><br><span class="line">print(cr)</span><br><span class="line"><span class="comment"># feature selection: improve model&#x27;s accuracy scores or to boost their performance on very high-dimensional dataset. </span></span><br><span class="line"><span class="comment">#1. removing features with low variance (Variance Threshold): a simple baseline approach for feature selection. It removes all features whose variance </span></span><br><span class="line"><span class="comment"># does not meet some threshold. By default, it removes all zero-variance features. Var[X] = p(1-p) (p is a parameter). Assume p =. 0.8, threshold = 0.16 </span></span><br><span class="line"><span class="comment"># Univariate feature selection</span></span><br><span class="line"><span class="comment"># recursive feature elimination</span></span><br></pre></td></tr></table></figure>

<pre><code>Training Accuracy : 1.0
Testing Accuracy : 0.8957622990745251
              precision    recall  f1-score   support

           0       0.91      0.97      0.94      3425
           1       0.76      0.54      0.63       681

    accuracy                           0.90      4106
   macro avg       0.84      0.76      0.79      4106
weighted avg       0.89      0.90      0.89      4106</code></pre>
<p><img src="/2020/10/14/Coding-Demonstration/output_23_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># what is model?</span></span><br><span class="line"><span class="comment"># model = parameters + mathematical equations </span></span><br><span class="line"><span class="comment"># parameters: numeric values </span></span><br><span class="line"><span class="comment"># mathematical equations: </span></span><br><span class="line"><span class="comment"># y = ax + b </span></span><br><span class="line"><span class="comment"># logistic regression: </span></span><br><span class="line"><span class="comment"># 1. regression 2. classfication 3. clustering </span></span><br><span class="line"><span class="comment"># n input: x_1, x_2, x_3, ...., x_n</span></span><br><span class="line"><span class="comment"># one output: y </span></span><br><span class="line"><span class="comment"># Step 1: y_t = a_1 * x_1 + a_2 * x_2 + a_3 * x_3 + ... + a_n * x_n </span></span><br><span class="line"><span class="comment"># Step 2: y = 1/ (e^(-1 * y_t) + 1) -&gt; non-linear transformation -&gt; sigmoid function -&gt; (deep neural network (深度神经网络)) optional </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">model_logistic = LogisticRegression(random_state = <span class="number">0</span>)</span><br><span class="line">sel = VarianceThreshold(threshold = (<span class="number">0.7</span> * (<span class="number">1</span> - <span class="number">0.70</span>)))</span><br><span class="line">sel.fit_transform(x)</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = <span class="number">0.333</span>, random_state = <span class="number">0</span>)</span><br><span class="line">model_logistic.fit(x_train, y_train) <span class="comment"># train logistic regression model </span></span><br><span class="line"><span class="comment"># this the model predict result </span></span><br><span class="line">y_predict = model_logistic.predict(x_test)</span><br><span class="line"><span class="keyword">print</span> (y_predict)</span><br><span class="line">y_predict_prob = model_logistic.predict_proba(x_test)</span><br><span class="line"><span class="keyword">print</span> (y_predict_prob)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="comment"># evaluating the model</span></span><br><span class="line">print(<span class="string">&quot;Training Accuracy :&quot;</span>, model_logistic.score(x_train, y_train))</span><br><span class="line">print(<span class="string">&quot;Testing Accuracy :&quot;</span>, model_logistic.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Homework (optional): confusion matrix </span></span><br><span class="line"><span class="comment"># confusion matrix</span></span><br><span class="line">cm = confusion_matrix(y_test, y_predict)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">sns.heatmap(cm ,annot = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># classification report</span></span><br><span class="line">cr = classification_report(y_test, y_predict)</span><br><span class="line">print(cr)</span><br></pre></td></tr></table></figure>

<pre><code>/Users/hanzhongzheng/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)


[0 0 0 ... 0 0 0]
[[0.83184852 0.16815148]
 [0.98105635 0.01894365]
 [0.97487663 0.02512337]
 ...
 [0.96053267 0.03946733]
 [0.8637038  0.1362962 ]
 [0.96536665 0.03463335]]
Training Accuracy : 0.8877675097276264
Testing Accuracy : 0.8753044325377496
              precision    recall  f1-score   support

           0       0.89      0.97      0.93      3425
           1       0.74      0.38      0.50       681

    accuracy                           0.88      4106
   macro avg       0.81      0.68      0.72      4106
weighted avg       0.86      0.88      0.86      4106</code></pre>
<p><img src="/2020/10/14/Coding-Demonstration/output_24_2.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SVM: support vector machine (支持向量机)</span></span><br><span class="line"><span class="comment"># support vector: the points that are the closest to the classifier lines </span></span><br><span class="line"><span class="comment"># objective: adding the distance of all support vectors until it is minimized. When the total distance is minized, then we find the optimal line to </span></span><br><span class="line"><span class="comment">#successfully classify the two kinds of points (samples)</span></span><br><span class="line"><span class="comment"># kernel function </span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">s_v_m = svm.SVC(probability=<span class="literal">True</span>)</span><br><span class="line">sel = VarianceThreshold(threshold = (<span class="number">0.7</span> * (<span class="number">1</span> - <span class="number">0.70</span>)))</span><br><span class="line">sel.fit_transform(x)</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = <span class="number">0.333</span>, random_state = <span class="number">0</span>)</span><br><span class="line">s_v_m.fit(x_train, y_train)</span><br><span class="line">y_predict = s_v_m.predict(x_test)</span><br><span class="line">y_predic_prob = s_v_m.predict_proba(x_test)</span><br><span class="line">print(y_predic_prob)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="comment"># evaluating the model</span></span><br><span class="line">print(<span class="string">&quot;Training Accuracy :&quot;</span>, s_v_m.score(x_train, y_train))</span><br><span class="line">print(<span class="string">&quot;Testing Accuracy :&quot;</span>, s_v_m.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Homework (optional): confusion matrix </span></span><br><span class="line"><span class="comment"># confusion matrix</span></span><br><span class="line">cm = confusion_matrix(y_test, y_predict)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">sns.heatmap(cm ,annot = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># classification report</span></span><br><span class="line">cr = classification_report(y_test, y_predict)</span><br><span class="line">print(cr)</span><br></pre></td></tr></table></figure>

<pre><code>[[0.91192693 0.08807307]
 [0.85601594 0.14398406]
 [0.92533649 0.07466351]
 ...
 [0.91286153 0.08713847]
 [0.91532365 0.08467635]
 [0.91266954 0.08733046]]
Training Accuracy : 0.8521400778210116
Testing Accuracy : 0.8360935216755967
              precision    recall  f1-score   support

           0       0.84      1.00      0.91      3425
           1       1.00      0.01      0.02       681

    accuracy                           0.84      4106
   macro avg       0.92      0.51      0.47      4106
weighted avg       0.86      0.84      0.76      4106</code></pre>
<p><img src="/2020/10/14/Coding-Demonstration/output_25_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># deep learning (深度学习): </span></span><br><span class="line"><span class="comment"># deep neural network: simulate human brain </span></span><br><span class="line"><span class="comment"># activation function (激活函数)-&gt; non-linear transformation functions </span></span><br><span class="line"><span class="comment">#1. sigmoid: range: (0, 1) : 1/(e^(-1) + 1)</span></span><br><span class="line"><span class="comment">#2. Relu: range: [0, infinite]</span></span><br><span class="line"><span class="comment"># when x&lt;=0, y = 0; when x&gt;0; y = x</span></span><br><span class="line"><span class="comment">#3. tanh: range(-1, 1)</span></span><br><span class="line"><span class="comment">#4. softmax: range (0, 1) -&gt; probaility prediction purpose, aims for multi-class prediction</span></span><br><span class="line"><span class="comment"># parameters</span></span><br><span class="line"><span class="comment"># classical model: 几十万～100万</span></span><br><span class="line"><span class="comment"># the state-of-the-art model：8million</span></span><br><span class="line"><span class="comment"># over-fitting vs. under-fitting? homework 1</span></span><br><span class="line"><span class="comment"># homework 2: implement feature selection using variance threshold on logistic regression model and SVM model. </span></span><br><span class="line"><span class="comment"># ROC and AUC </span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> metrics</span><br><span class="line">fpr, tpr, threshold = metrics.roc_curve(y_test, y_predic_prob[:,<span class="number">1</span>])</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.title(<span class="string">&#x27;Receiver Operating Characteristic&#x27;</span>)</span><br><span class="line">plt.plot(fpr, tpr, <span class="string">&#x27;b&#x27;</span>, label = <span class="string">&#x27;AUC = %0.2f&#x27;</span> % roc_auc)</span><br><span class="line">plt.legend(loc = <span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>],<span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">plt.xlim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.ylim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True Positive Rate&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/2020/10/14/Coding-Demonstration/output_27_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line">nn_model = MLPClassifier(random_state=<span class="number">1</span>, max_iter=<span class="number">1000</span>)</span><br><span class="line">print(nn_model)</span><br></pre></td></tr></table></figure>

<pre><code>MLPClassifier(max_iter=1000, random_state=1)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">nn_model.fit(x_train, y_train)</span><br><span class="line">predict = nn_model.predict(x_test)</span><br><span class="line">predict_prob = nn_model.predict_proba(x_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="comment"># evaluating the model</span></span><br><span class="line">print(<span class="string">&quot;Training Accuracy :&quot;</span>, nn_model.score(x_train, y_train))</span><br><span class="line">print(<span class="string">&quot;Testing Accuracy :&quot;</span>, nn_model.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Homework (optional): confusion matrix </span></span><br><span class="line"><span class="comment"># confusion matrix</span></span><br><span class="line">cm = confusion_matrix(y_test, predict)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">sns.heatmap(cm ,annot = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># classification report</span></span><br><span class="line">cr = classification_report(y_test, predict)</span><br><span class="line">print(cr)</span><br></pre></td></tr></table></figure>

<pre><code>Training Accuracy : 0.8927529182879378
Testing Accuracy : 0.8838285435947394
              precision    recall  f1-score   support

           0       0.89      0.98      0.93      3425
           1       0.78      0.42      0.54       681

    accuracy                           0.88      4106
   macro avg       0.84      0.70      0.74      4106
weighted avg       0.88      0.88      0.87      4106</code></pre>
<p><img src="/2020/10/14/Coding-Demonstration/output_29_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">fpr, tpr, threshold = metrics.roc_curve(y_test, predict_prob[:,<span class="number">1</span>])</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.title(<span class="string">&#x27;Receiver Operating Characteristic&#x27;</span>)</span><br><span class="line">plt.plot(fpr, tpr, <span class="string">&#x27;b&#x27;</span>, label = <span class="string">&#x27;AUC = %0.2f&#x27;</span> % roc_auc)</span><br><span class="line">plt.legend(loc = <span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>],<span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">plt.xlim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.ylim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True Positive Rate&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/2020/10/14/Coding-Demonstration/output_30_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>
    <br>
    <br>
    <a href="http://example.com/2020/10/14/Coding-Demonstration/" class="more">Read more <i class="icon-angle-right"></i></a>
  </div>
</div>
<hr class="blog-post-sep">

      
	<div class="row">
  <div class="col-md-4 col-sm-4">
    
  </div>
  
    <div class="col-xs-12">
  
    
    <h2 itemprop="name">
      <a class="archive-article-title" href="/2020/10/14/Project-Summary/">Project Summary</a>
    </h2>


    <ul class="blog-info">
      <li>
      	<i class="fa fa-calendar"></i> 
        <time datetime="2020-10-14T07:18:54.000Z" itemprop="datePublished">2020/10/14</time>

      </li>
      <li><i class="fa fa-comments"></i>
        <a href="http://example.com/2020/10/14/Project-Summary/#disqus_thread" class="article-comment-link">Comments</a>
      </li>
      <li>
	<i class="fa fa-tags"></i>
	

      </li>
    </ul>
    <div class="blog-item">
      
	<style>

    .p {
        text-indent:2em;
        text-align:justify;

    }

</style>

<p class="p">
My project is a python program aiming to help business find their chance of returned consumer. The program considers various independent variables: data including, administrative, administrative duration, amount of substitute, bounce rate, exit rate and so on, which all serves to provide a precise result. In summary, the process of the model building was a big challenge for me. I had significant difficulty in learning python at the beginning of the program as I have not learned any computer languages before. However, I asked for help from teachers, students and took online courses and used one whole month to understand the basic rules to apply python by myself. What’s more, when I finished my model, I needed some data to test if the model worked or needed some improvement instead. It took me some time to get in touch with a manager in a large internet company, which the manager is a friend of my mother. But the manager was a little bit of worried about the risk of sharing data with me, as some privacy data might be not available for sharing. After a week’s negotiation, I persuaded him and proved him that the data I needed was all aside from the core data. Eventually he agreed to offer me the data but I had to do the model on their company’s computer. After a months’ test, the model was proved to be successful and the manager wrote me an official email to appreciate my work. 
</p>

<hr>

<p><a href="online_shoppers_intention.csv">Dataset Download</a></p>

      
    </div>
    <br>
    <br>
    <a href="http://example.com/2020/10/14/Project-Summary/" class="more">Read more <i class="icon-angle-right"></i></a>
  </div>
</div>
<hr class="blog-post-sep">

      
    </div>
    
      <div id="page-nav" class="pagination">
	<span class="page-number current">1</span>
      </div>
    
  </section>

</div>

</div>

  </div>
  </div>



  
    <!-- BEGIN FOOTER -->
    <div class="footer">
      <div class="container">
        <div class="row">
          <!-- BEGIN COPYRIGHT -->
          <div class="col-md-6 col-sm-6 padding-top-10">
                  &copy; 2020 Kuzma&#39;s Blog<br>
 <a href="javascript:;">Privacy Policy</a> | <a href="javascript:;">Terms of Service</a>
          </div>
          <!-- END COPYRIGHT -->
	  <!-- BEGIN SOCIAL -->
<div class="col-md-6 col-sm-6">
  <ul class="social-footer list-unstyled list-inline pull-right">
    
      <li><a target="_blank" rel="noopener" href="https://github.com/Kuz03"><i class="fa fa-github"></i></a></li>
    
  </ul>  
</div>
<!-- END SOCIAL -->

        </div>
      </div>
    </div>
    <!-- END FOOTER -->

  <!-- BEGIN CORE PLUGINS (REQUIRED FOR ALL PAGES) -->
<!--[if lt IE 9]>

<script src="/metronic/assets/plugins/respond.min.js"></script>

<![endif]--> 

<script src="/metronic/assets/plugins/jquery.min.js"></script>


<script src="/metronic/assets/plugins/jquery-migrate.min.js"></script>


<script src="/metronic/assets/plugins/bootstrap/js/bootstrap.min.js"></script>


<script src="/metronic/assets/corporate/scripts/back-to-top.js"></script>


<script src="/metronic/assets/plugins/owl.carousel/owl.carousel.min.js"></script>


<script src="/metronic/assets/corporate/scripts/layout.js"></script>


<script src="/js/wow.min.js"></script>



  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<script type="text/javascript">
    jQuery(document).ready(function() {
        Layout.init();    
        Layout.initOWL();
        Layout.initTwitter();
        Layout.initFixHeaderWithPreHeader(); /* Switch On Header Fixing (only if you have pre-header) */
        Layout.initNavScrolling(); 
	new WOW().init();
    });
</script>
<!-- END CORE PLUGINS -->

<!-- BEGIN PAGE-SPECIFIC PLUGINS --> 







<!-- END PAGE-SPECIFIC PLUGINS --> 

<!-- BEGIN INTEGRATIONS -->





<!-- END INTEGRATIONS -->

</body>
</html>
